{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Django Interview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- https://devinterview.io/questions/web-and-mobile-development/django-interview-questions/ -->\n",
    "\n",
    "<!-- https://chatgpt.com/g/g-LCO79N7QT-django-copilot/c/679e6230-aea8-8004-b542-c129eba0db01 -->\n",
    "\n",
    "<!-- https://chatgpt.com/c/679e96db-1f08-8004-b7ea-cdbb7545ff35 -->\n",
    "\n",
    "<!-- https://hackr.io/blog/top-django-interview-questions-and-answers -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "\n",
    "# <!-- https://chatgpt.com/g/g-LCO79N7QT-django-copilot/c/679e6230-aea8-8004-b542-c129eba0db01 -->\n",
    "\n",
    "# <!-- https://chatgpt.com/c/679e96db-1f08-8004-b7ea-cdbb7545ff35 -->\n",
    "\n",
    "# <!-- https://hackr.io/blog/top-django-interview-questions-and-answers -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date format not recognized: 08-02-2025 01:17:01\n",
      "2025-02-08 01:17:01 -> 45696.0534837963\n",
      "08/02/2025 -> 45696.0\n",
      "20250208011701 -> 45696.0534837963\n",
      "08-02-25 01:17 -> 45696.0534722222\n",
      "02/08/25 01:17:01 -> 45871.0534837963\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# List of possible datetime formats\n",
    "DATE_FORMATS = [\n",
    "    \"%Y-%m-%d %H:%M:%S\", \"%d/%m/%Y %H:%M:%S\", \"%Y-%m-%d\", \"%d-%m-%Y\", \n",
    "    \"%d-%m-%Y %H:%M\", \"%d/%m/%Y %H:%M\", \"%Y%m%d%H%M%S\", \"%Y%m%d%H%M\", \n",
    "    \"%d/%m/%Y\", \"%Y-%m-%d %I:%M:%S %p\", \"%d/%m/%Y %I:%M:%S %p\", \n",
    "    \"%Y-%m-%d %I:%M %p\", \"%d/%m/%Y %I:%M %p\", \"%d/%m/%y %H:%M:%S\", \n",
    "    \"%d-%m-%y %H:%M:%S\", \"%d-%m-%y %H:%M\", \"%m/%d/%y %H:%M:%S\", \n",
    "    \"%m-%d-%y %H:%M:%S\", \"%m-%d-%y %H:%M\", \"%m/%d/%Y\"\n",
    "]\n",
    "\n",
    "def datetime_to_serial(date_str):\n",
    "    base_date = datetime(1899, 12, 30)  # Excel's base date\n",
    "    \n",
    "    for fmt in DATE_FORMATS:\n",
    "        try:\n",
    "            dt = datetime.strptime(date_str, fmt)\n",
    "            serial_date = (dt - base_date).total_seconds() / 86400  # Convert to days\n",
    "            return round(serial_date, 10)  # Limit decimal places for precision\n",
    "        except ValueError:\n",
    "            continue  # Try next format\n",
    "    \n",
    "    raise ValueError(f\"Date format not recognized: {date_str}\")\n",
    "\n",
    "# Example usage\n",
    "date_strings = [\n",
    "    \"08-02-2025 01:17:01\", \"2025-02-08 01:17:01\", \"08/02/2025\", \n",
    "    \"20250208011701\", \"08-02-25 01:17\", \"02/08/25 01:17:01\"\n",
    "]\n",
    "\n",
    "for date_string in date_strings:\n",
    "    try:\n",
    "        print(f\"{date_string} -> {datetime_to_serial(date_string)}\")\n",
    "    except ValueError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved as: output3.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# List of possible datetime formats\n",
    "DATE_FORMATS = [\n",
    "    \"%Y-%m-%d %H:%M:%S\", \"%d/%m/%Y %H:%M:%S\", \"%Y-%m-%d\", \"%d-%m-%Y\",\n",
    "    \"%d-%m-%Y %H:%M\", \"%d/%m/%Y %H:%M\", \"%Y%m%d%H%M%S\", \"%Y%m%d%H%M\",\n",
    "    \"%d/%m/%Y\", \"%Y-%m-%d %I:%M:%S %p\", \"%d/%m/%Y %I:%M:%S %p\",\n",
    "    \"%Y-%m-%d %I:%M %p\", \"%d/%m/%Y %I:%M %p\", \"%d/%m/%y %H:%M:%S\",\n",
    "    \"%d-%m-%y %H:%M:%S\", \"%d-%m-%y %H:%M\", \"%m/%d/%y %H:%M:%S\",\n",
    "    \"%m-%d-%y %H:%M:%S\", \"%m-%d-%y %H:%M\", \"%m/%d/%Y\"\n",
    "]\n",
    "\n",
    "def datetime_to_serial(date_str):\n",
    "    base_date = datetime(1899, 12, 30)  # Excel's base date\n",
    "    \n",
    "    for fmt in DATE_FORMATS:\n",
    "        try:\n",
    "            dt = datetime.strptime(date_str, fmt)\n",
    "            serial_date = (dt - base_date).total_seconds() / 86400  # Convert to days\n",
    "            return round(serial_date, 10)  # Limit decimal places for precision\n",
    "        except ValueError:\n",
    "            continue  # Try next format\n",
    "    \n",
    "    # If parsing fails, return the current date-time in serial format\n",
    "    current_serial = (datetime.now() - base_date).total_seconds() / 86400\n",
    "    return round(current_serial, 10)\n",
    "\n",
    "def process_csv(input_file, output_file):\n",
    "    # Read CSV\n",
    "    df = pd.read_csv(input_file, dtype=str)  # Read all as strings to avoid errors\n",
    "    \n",
    "    # Ensure \"File_Save_Date\" column exists\n",
    "    if \"File_Save_Date\" not in df.columns:\n",
    "        raise KeyError(\"The column 'File_Save_Date' is missing in the CSV file.\")\n",
    "    \n",
    "    # Apply conversion function to each row in \"File_Save_Date\"\n",
    "    df[\"File_Save_Date\"] = df[\"File_Save_Date\"].apply(lambda x: datetime_to_serial(str(x).strip()))\n",
    "    \n",
    "    # Save processed data to output CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Processed file saved as: {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "input_csv = \"Book1.csv\"   # Replace with your actual input CSV file path\n",
    "output_csv = \"output3.csv\" # Replace with desired output CSV file path\n",
    "\n",
    "process_csv(input_csv, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved as: output5.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# List of possible datetime formats\n",
    "DATE_FORMATS = [\n",
    "    \"%Y-%m-%d %H:%M:%S\", \"%d/%m/%Y %H:%M:%S\", \"%Y-%m-%d\", \"%d-%m-%Y\",\n",
    "    \"%d-%m-%Y %H:%M\", \"%d/%m/%Y %H:%M\", \"%Y%m%d%H%M%S\", \"%Y%m%d%H%M\",\n",
    "    \"%d/%m/%Y\", \"%Y-%m-%d %I:%M:%S %p\", \"%d/%m/%Y %I:%M:%S %p\",\n",
    "    \"%Y-%m-%d %I:%M %p\", \"%d/%m/%Y %I:%M %p\", \"%d/%m/%y %H:%M:%S\",\n",
    "    \"%d-%m-%y %H:%M:%S\", \"%d-%m-%y %H:%M\", \"%m/%d/%y %H:%M:%S\",\n",
    "    \"%m-%d-%y %H:%M:%S\", \"%m-%d-%y %H:%M\", \"%m/%d/%Y\"\n",
    "]\n",
    "\n",
    "def datetime_to_serial(date_str):\n",
    "    \"\"\"Convert various date formats to Excel serial date format.\"\"\"\n",
    "    base_date = datetime(1899, 12, 30)  # Excel's base date\n",
    "    \n",
    "    for fmt in DATE_FORMATS:\n",
    "        try:\n",
    "            dt = datetime.strptime(date_str, fmt)\n",
    "            serial_date = (dt - base_date).total_seconds() / 86400  # Convert to days\n",
    "            return round(serial_date, 10)  # Limiting decimal places\n",
    "        except ValueError:\n",
    "            continue  # Try next format\n",
    "    \n",
    "    return None  # Return None if no format matches\n",
    "\n",
    "def process_csv(input_csv, output_csv):\n",
    "    \"\"\"Read CSV, convert File_Save_Date to serial format, and save new CSV.\"\"\"\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    if 'File_Save_Date' not in df.columns:\n",
    "        raise KeyError(\"The column 'File_Save_Date' is missing from the CSV file.\")\n",
    "\n",
    "    # Convert the 'File_Save_Date' column\n",
    "    df['Serial_File_Save_Date'] = df['File_Save_Date'].astype(str).apply(datetime_to_serial)\n",
    "\n",
    "    # Save the modified CSV\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Processed file saved as: {output_csv}\")\n",
    "\n",
    "# Example usage\n",
    "input_csv_path = \"Book1.csv\"  # Change this to your actual input file\n",
    "output_csv_path = \"output5.csv\"\n",
    "process_csv(input_csv_path, output_csv_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved as: output6.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "def datetime_to_serial(date_str):\n",
    "    \"\"\"Automatically detect and convert date strings to Excel serial date format.\"\"\"\n",
    "    base_date = datetime(1899, 12, 30)  # Excel's base date\n",
    "\n",
    "    try:\n",
    "        # Automatically parse the date format\n",
    "        dt = parser.parse(date_str, dayfirst=True)  # Set dayfirst=True to handle dd/mm/yyyy cases\n",
    "        serial_date = (dt - base_date).total_seconds() / 86400  # Convert to Excel serial format\n",
    "        return round(serial_date, 10)  # Limiting decimal places\n",
    "    except (ValueError, TypeError):\n",
    "        return None  # Return None if parsing fails\n",
    "\n",
    "def process_csv(input_csv, output_csv):\n",
    "    \"\"\"Read CSV, convert File_Save_Date to serial format, and save new CSV.\"\"\"\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    if 'File_Save_Date' not in df.columns:\n",
    "        raise KeyError(\"The column 'File_Save_Date' is missing from the CSV file.\")\n",
    "\n",
    "    # Convert the 'File_Save_Date' column\n",
    "    df['Serial_File_Save_Date'] = df['File_Save_Date'].astype(str).apply(datetime_to_serial)\n",
    "\n",
    "    # Save the modified CSV\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Processed file saved as: {output_csv}\")\n",
    "\n",
    "# Example usage\n",
    "input_csv_path = \"Book1.csv\"  # Change this to your actual input file\n",
    "output_csv_path = \"output6.csv\"\n",
    "process_csv(input_csv_path, output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"00:34:51.200000\" doesn't match format \"%d-%m-%Y %H:%M:%S\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(file_path)  \u001b[38;5;66;03m# Change to pd.read_csv(file_path) for CSV\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Apply conversion logic to the 'File_save_date' column\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile_Save_Date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFile_Save_Date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_to_serial_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Save back to the same file (overwrite)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m df\u001b[38;5;241m.\u001b[39mto_excel(file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# Change to df.to_csv(file_path, index=False) for CSV\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[17], line 6\u001b[0m, in \u001b[0;36mconvert_to_serial_date\u001b[1;34m(date_str)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert a datetime string to Excel serial date format.\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m base_date \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1899-12-30\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Excel base date\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m dt \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mH:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert to datetime\u001b[39;00m\n\u001b[0;32m      7\u001b[0m serial_date \u001b[38;5;241m=\u001b[39m (dt \u001b[38;5;241m-\u001b[39m base_date)\u001b[38;5;241m.\u001b[39mtotal_seconds() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m86400\u001b[39m  \u001b[38;5;66;03m# Convert to serial format\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m serial_date\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\tools\\datetimes.py:1101\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1099\u001b[0m         result \u001b[38;5;241m=\u001b[39m convert_listlike(argc, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1101\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43marg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, np\u001b[38;5;241m.\u001b[39mbool_):\n\u001b[0;32m   1103\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(result)  \u001b[38;5;66;03m# TODO: avoid this kludge.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\tools\\datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[0;32m    436\u001b[0m     arg,\n\u001b[0;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    442\u001b[0m )\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\tools\\datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    457\u001b[0m     arg,\n\u001b[0;32m    458\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data \"00:34:51.200000\" doesn't match format \"%d-%m-%Y %H:%M:%S\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_to_serial_date(date_str):\n",
    "    \"\"\"Convert a datetime string to Excel serial date format.\"\"\"\n",
    "    base_date = pd.Timestamp(\"1899-12-30\")  # Excel base date\n",
    "    dt = pd.to_datetime(date_str, format=\"%d-%m-%Y %H:%M:%S\")  # Convert to datetime\n",
    "    serial_date = (dt - base_date).total_seconds() / 86400  # Convert to serial format\n",
    "    return serial_date\n",
    "\n",
    "# Read input file\n",
    "file_path = \"Book1.xlsx\"  # Change to your file path\n",
    "df = pd.read_excel(file_path)  # Change to pd.read_csv(file_path) for CSV\n",
    "\n",
    "# Apply conversion logic to the 'File_save_date' column\n",
    "df['File_Save_Date'] = df['File_Save_Date'].apply(convert_to_serial_date)\n",
    "\n",
    "# Save back to the same file (overwrite)\n",
    "df.to_excel(file_path, index=False)  # Change to df.to_csv(file_path, index=False) for CSV\n",
    "\n",
    "print(\"File updated successfully with converted dates.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "     -------------------------------------- 250.9/250.9 kB 1.4 MB/s eta 0:00:00\n",
      "Collecting et-xmlfile\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing '34:51.2': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '34:51.2': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '34:51.2': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '34:51.2': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '34:51.2': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '34:51.2': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '34:51.2': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '34:51.2': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '34:51.2': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '34:51.2': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '36:32.4': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '36:32.4': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '36:32.4': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '36:32.4': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '36:32.4': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '36:32.4': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '36:32.4': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '36:32.4': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '36:32.4': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '36:32.4': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '36:32.4': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '36:32.4': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '38:53.6': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '38:53.6': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '38:53.6': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '38:53.6': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '38:53.6': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '38:53.6': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '38:53.6': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '38:53.6': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '38:53.6': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '38:53.6': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '38:53.6': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '38:53.6': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '38:53.6': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '38:53.6': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '38:53.6': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '38:53.6': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '38:53.6': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '39:42.8': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '39:42.8': 'NaTType' object has no attribute 'normalize'\n",
      "Error parsing '39:42.8': 'NaTType' object has no attribute 'normalize'\n",
      "File successfully saved as output_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_to_serial_date(date_str):\n",
    "    \"\"\"Convert a date-time string to Excel serial date format, handling different cases.\"\"\"\n",
    "    base_date = pd.Timestamp(\"1899-12-30\")  # Excel base date\n",
    "\n",
    "    try:\n",
    "        if \":\" in date_str and \"-\" not in date_str:  # If it's only a time value\n",
    "            dt = pd.to_datetime(date_str, format=\"%H:%M:%S.%f\", errors=\"coerce\")\n",
    "            dt = pd.Timestamp.today().normalize() + (dt - dt.normalize())  # Use today's date\n",
    "        else:\n",
    "            dt = pd.to_datetime(date_str, format=\"%d-%m-%Y %H:%M:%S\", errors=\"coerce\")\n",
    "        \n",
    "        if pd.isnull(dt):  # Handle invalid values\n",
    "            return None\n",
    "        \n",
    "        serial_date = (dt - base_date).total_seconds() / 86400  # Convert to serial format\n",
    "        return serial_date\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing '{date_str}': {e}\")\n",
    "        return None\n",
    "\n",
    "# File paths\n",
    "input_file = \"Book1.csv\"   # Change this to your actual input file\n",
    "output_file = \"output_data.csv\"  # Output file\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(input_file, dtype=str)  # Read as string to avoid auto-parsing issues\n",
    "\n",
    "# Apply conversion to 'File_save_date' column\n",
    "df['File_Save_Date'] = df['File_Save_Date'].astype(str).apply(convert_to_serial_date)\n",
    "\n",
    "# Save the updated data to a new CSV file\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"File successfully saved as {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
